{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing all libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from bayes_opt import BayesianOptimization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disable all warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Enable warnings again\n",
    "## warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finished = pd.read_csv('data_finish_prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verschil_Lengte</th>\n",
       "      <th>verschil_Gewicht</th>\n",
       "      <th>verschil_6 MWT</th>\n",
       "      <th>verschil_TUG</th>\n",
       "      <th>verschil_BMI</th>\n",
       "      <th>verschil_Conditie</th>\n",
       "      <th>verschil_Lenigheid</th>\n",
       "      <th>verschil_Knijpkracht</th>\n",
       "      <th>NederlandseAntillenEnAruba</th>\n",
       "      <th>GeboorteRelatief</th>\n",
       "      <th>...</th>\n",
       "      <th>Ondergewicht</th>\n",
       "      <th>MatigOvergewicht</th>\n",
       "      <th>ErnstigOvergewichtObesitas</th>\n",
       "      <th>VoldoetAanBeweegrichtlijn</th>\n",
       "      <th>Mantelzorger</th>\n",
       "      <th>ZwaarBelasteMantelzorgers</th>\n",
       "      <th>UrenMantelzorgPerWeek</th>\n",
       "      <th>Rokers</th>\n",
       "      <th>VoldoetAanRichtlijnAlcoholgebruik</th>\n",
       "      <th>OvermatigDrinker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>-0.906068</td>\n",
       "      <td>-0.125200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.8</td>\n",
       "      <td>-0.063003</td>\n",
       "      <td>-0.933187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570059</td>\n",
       "      <td>0.531251</td>\n",
       "      <td>0.934008</td>\n",
       "      <td>-0.796811</td>\n",
       "      <td>0.94649</td>\n",
       "      <td>-0.053768</td>\n",
       "      <td>-0.233017</td>\n",
       "      <td>1.074978</td>\n",
       "      <td>0.932579</td>\n",
       "      <td>-0.702505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>-104.0</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>-3.133140</td>\n",
       "      <td>-0.384503</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>-0.063003</td>\n",
       "      <td>-0.933187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570059</td>\n",
       "      <td>0.531251</td>\n",
       "      <td>0.934008</td>\n",
       "      <td>-0.796811</td>\n",
       "      <td>0.94649</td>\n",
       "      <td>-0.053768</td>\n",
       "      <td>-0.233017</td>\n",
       "      <td>1.074978</td>\n",
       "      <td>0.932579</td>\n",
       "      <td>-0.702505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>-2.143719</td>\n",
       "      <td>0.080729</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-0.063003</td>\n",
       "      <td>-0.933187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570059</td>\n",
       "      <td>0.531251</td>\n",
       "      <td>0.934008</td>\n",
       "      <td>-0.796811</td>\n",
       "      <td>0.94649</td>\n",
       "      <td>-0.053768</td>\n",
       "      <td>-0.233017</td>\n",
       "      <td>1.074978</td>\n",
       "      <td>0.932579</td>\n",
       "      <td>-0.702505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-2.07</td>\n",
       "      <td>-0.521359</td>\n",
       "      <td>0.020537</td>\n",
       "      <td>4.25</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-0.063003</td>\n",
       "      <td>-0.933187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570059</td>\n",
       "      <td>0.531251</td>\n",
       "      <td>0.934008</td>\n",
       "      <td>-0.796811</td>\n",
       "      <td>0.94649</td>\n",
       "      <td>-0.053768</td>\n",
       "      <td>-0.233017</td>\n",
       "      <td>1.074978</td>\n",
       "      <td>0.932579</td>\n",
       "      <td>-0.702505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.221264</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-0.063003</td>\n",
       "      <td>-0.933187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570059</td>\n",
       "      <td>0.531251</td>\n",
       "      <td>0.934008</td>\n",
       "      <td>-0.796811</td>\n",
       "      <td>0.94649</td>\n",
       "      <td>-0.053768</td>\n",
       "      <td>-0.233017</td>\n",
       "      <td>1.074978</td>\n",
       "      <td>0.932579</td>\n",
       "      <td>-0.702505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   verschil_Lengte  verschil_Gewicht  verschil_6 MWT  verschil_TUG  \\\n",
       "0              0.0              -2.3           -52.0          2.94   \n",
       "1              0.0              -7.2          -104.0         -2.43   \n",
       "2              1.0              -4.9            63.0         -1.92   \n",
       "3              0.0              -1.3            23.0         -2.07   \n",
       "4              0.0               2.0           126.0          0.69   \n",
       "\n",
       "   verschil_BMI  verschil_Conditie  verschil_Lenigheid  verschil_Knijpkracht  \\\n",
       "0     -0.906068          -0.125200                 NaN                  30.8   \n",
       "1     -3.133140          -0.384503               -4.00                  11.5   \n",
       "2     -2.143719           0.080729                7.50                   2.7   \n",
       "3     -0.521359           0.020537                4.25                  -1.7   \n",
       "4      0.800000           0.221264               -2.50                   5.5   \n",
       "\n",
       "   NederlandseAntillenEnAruba  GeboorteRelatief  ...  Ondergewicht  \\\n",
       "0                   -0.063003         -0.933187  ...      0.570059   \n",
       "1                   -0.063003         -0.933187  ...      0.570059   \n",
       "2                   -0.063003         -0.933187  ...      0.570059   \n",
       "3                   -0.063003         -0.933187  ...      0.570059   \n",
       "4                   -0.063003         -0.933187  ...      0.570059   \n",
       "\n",
       "   MatigOvergewicht  ErnstigOvergewichtObesitas  VoldoetAanBeweegrichtlijn  \\\n",
       "0          0.531251                    0.934008                  -0.796811   \n",
       "1          0.531251                    0.934008                  -0.796811   \n",
       "2          0.531251                    0.934008                  -0.796811   \n",
       "3          0.531251                    0.934008                  -0.796811   \n",
       "4          0.531251                    0.934008                  -0.796811   \n",
       "\n",
       "   Mantelzorger  ZwaarBelasteMantelzorgers  UrenMantelzorgPerWeek    Rokers  \\\n",
       "0       0.94649                  -0.053768              -0.233017  1.074978   \n",
       "1       0.94649                  -0.053768              -0.233017  1.074978   \n",
       "2       0.94649                  -0.053768              -0.233017  1.074978   \n",
       "3       0.94649                  -0.053768              -0.233017  1.074978   \n",
       "4       0.94649                  -0.053768              -0.233017  1.074978   \n",
       "\n",
       "   VoldoetAanRichtlijnAlcoholgebruik  OvermatigDrinker  \n",
       "0                           0.932579         -0.702505  \n",
       "1                           0.932579         -0.702505  \n",
       "2                           0.932579         -0.702505  \n",
       "3                           0.932579         -0.702505  \n",
       "4                           0.932579         -0.702505  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_finished.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finished.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dataframes for each dependent variable\n",
    "\n",
    "# Fixing 6MWT column name\n",
    "df_finished = df_finished.rename(columns={'verschil_6 MWT': 'verschil_6_MWT'})\n",
    "\n",
    "# Verschil in gewicht\n",
    "df_target_gewicht = df_finished['verschil_Gewicht']\n",
    "df_test_Gewicht = df_finished.drop(['verschil_Gewicht'], axis=1)\n",
    "\n",
    "# Verschil in 6MWT\n",
    "df_target_6_MWT = df_finished['verschil_6_MWT']\n",
    "df_test_6_MWT = df_finished.drop(['verschil_6_MWT'], axis=1)\n",
    "\n",
    "# Verschil in TUG\n",
    "df_target_TUG = df_finished['verschil_TUG']\n",
    "df_test_TUG = df_finished.drop(['verschil_TUG'], axis=1)\n",
    "\n",
    "\n",
    "# Verschil in BMI\n",
    "df_target_BMI = df_finished['verschil_BMI']\n",
    "df_test_BMI = df_finished.drop(['verschil_BMI'], axis=1)\n",
    "\n",
    "\n",
    "# Verschil in Conditie\n",
    "df_target_Conditie = df_finished['verschil_Conditie']\n",
    "df_test_Conditie = df_finished.drop(['verschil_Conditie'], axis=1)\n",
    "\n",
    "\n",
    "# Verschil in Lenigheid\n",
    "df_target_Lenigheid = df_finished['verschil_Lenigheid']\n",
    "df_test_Lenigheid = df_finished.drop(['verschil_Lenigheid'], axis=1)\n",
    "\n",
    "\n",
    "# Verschil in Knijpkracht\n",
    "df_target_Knijpkracht = df_finished['verschil_Knijpkracht']\n",
    "df_test_Knijpkracht = df_finished.drop(['verschil_Knijpkracht'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1099\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows\n",
    "num_rows = df_finished.shape[0]\n",
    "\n",
    "# Print the number of rows\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for Verschil in Gewicht\n",
    "X_train_Gewicht, X_test_Gewicht, y_train_Gewicht, y_test_Gewicht = train_test_split(\n",
    "    df_test_Gewicht, df_target_gewicht, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split data for Verschil in 6MWT\n",
    "X_train_6_MWT, X_test_6_MWT, y_train_6_MWT, y_test_6_MWT = train_test_split(\n",
    "    df_test_6_MWT, df_target_6_MWT, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split data for Verschil in TUG\n",
    "X_train_TUG, X_test_TUG, y_train_TUG, y_test_TUG = train_test_split(\n",
    "    df_test_TUG, df_target_TUG, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split data for Verschil in BMI\n",
    "X_train_BMI, X_test_BMI, y_train_BMI, y_test_BMI = train_test_split(\n",
    "    df_test_BMI, df_target_BMI, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split data for Verschil in Conditie\n",
    "X_train_Conditie, X_test_Conditie, y_train_Conditie, y_test_Conditie = train_test_split(\n",
    "    df_test_Conditie, df_target_Conditie, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split data for Verschil in Lenigheid\n",
    "X_train_Lenigheid, X_test_Lenigheid, y_train_Lenigheid, y_test_Lenigheid = train_test_split(\n",
    "    df_test_Lenigheid, df_target_Lenigheid, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split data for Verschil in Knijpkracht\n",
    "X_train_Knijpkracht, X_test_Knijpkracht, y_train_Knijpkracht, y_test_Knijpkracht = train_test_split(\n",
    "    df_test_Knijpkracht, df_target_Knijpkracht, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Split data into training and testing sets\n",
    "# train_ratio = 0.8\n",
    "# train_size = int(train_ratio * num_rows)\n",
    "\n",
    "# X_train = X[:train_size]\n",
    "# y_train = y[:train_size]\n",
    "\n",
    "# # Test data\n",
    "# X_test = X[train_size:]\n",
    "# y_test = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the feature variables into X\n",
    "X = np.concatenate((X_train_Gewicht, X_train_6_MWT, X_train_TUG, X_train_BMI, X_train_Conditie, X_train_Lenigheid, X_train_Knijpkracht))\n",
    "\n",
    "# Concatenate the target variables into y\n",
    "y = np.concatenate((y_train_Gewicht, y_train_6_MWT, y_train_TUG, y_train_BMI, y_train_Conditie, y_train_Lenigheid, y_train_Knijpkracht))\n",
    "\n",
    "# Test data\n",
    "X_test = np.concatenate((X_test_Gewicht, X_test_6_MWT, X_test_TUG, X_test_BMI, X_test_Conditie, X_test_Lenigheid, X_test_Knijpkracht))\n",
    "y_test = np.concatenate((y_test_Gewicht, y_test_6_MWT, y_test_TUG, y_test_BMI, y_test_Conditie, y_test_Lenigheid, y_test_Knijpkracht))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(X))\n",
    "\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bo_params_generic(model, params, X_train, y_train):\n",
    "    # Create the model instance with the specified parameters\n",
    "    regressor = model(**params)\n",
    "    \n",
    "    # Assuming you have X_train, y_train defined for regression\n",
    "    scores = cross_val_score(regressor, X_train, y_train, cv=10, scoring='neg_root_mean_squared_error')\n",
    "    return -scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#results = dt_bo.maximize(n_iter=5, init_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Coefficients:\n",
      "Feature 50: 148.18228651982133\n",
      "Feature 60: -147.53045902153002\n",
      "Feature 33: 77.98641807699985\n",
      "Feature 54: 66.6448127066419\n",
      "Feature 34: 63.29586560353903\n",
      "Feature 59: -53.950473011576264\n",
      "Feature 32: 53.229963200358185\n",
      "Feature 35: -49.14526062800492\n",
      "Feature 30: -29.928311411819603\n",
      "Feature 58: 28.649953909340002\n",
      "Feature 45: 28.581497333744974\n",
      "Feature 55: 28.36333581776917\n",
      "Feature 65: 27.48371236077007\n",
      "Feature 31: -27.01639096894545\n",
      "Feature 57: 25.941948982519058\n",
      "Feature 56: 25.643573112531143\n",
      "Feature 29: -25.02547400814238\n",
      "Feature 9: -17.629037971976828\n",
      "Feature 14: 16.966229886396405\n",
      "Feature 38: -15.533730125218412\n",
      "Feature 47: -15.412505845506297\n",
      "Feature 40: 14.584594837611832\n",
      "Feature 51: -14.531648801348645\n",
      "Feature 28: 13.929463847988018\n",
      "Feature 74: -13.794527656437573\n",
      "Feature 62: -13.59782701125398\n",
      "Feature 52: -13.387682983132803\n",
      "Feature 73: -12.802850456650564\n",
      "Feature 46: 12.693166874416104\n",
      "Feature 48: 11.940274169104939\n",
      "Feature 43: 11.290722082790644\n",
      "Feature 37: 11.275013920111197\n",
      "Feature 66: 11.101167298108447\n",
      "Feature 11: -11.075227117256912\n",
      "Feature 42: 9.809978689802804\n",
      "Feature 53: -8.78469092877564\n",
      "Feature 68: 8.316605446616443\n",
      "Feature 44: 8.232295303501493\n",
      "Feature 76: -8.155340109676679\n",
      "Feature 36: 7.344378811613651\n",
      "Feature 10: 7.271823841973317\n",
      "Feature 12: 6.7657842437204705\n",
      "Feature 8: 6.7043529495675696\n",
      "Feature 72: 6.578335846650877\n",
      "Feature 16: -6.407008381319411\n",
      "Feature 39: -6.337753108246024\n",
      "Feature 13: -6.117016764256453\n",
      "Feature 21: 6.012100254529593\n",
      "Feature 41: 5.266257790191194\n",
      "Feature 61: 5.171660577991625\n",
      "Feature 17: 4.832599282238247\n",
      "Feature 69: -4.362707863674926\n",
      "Feature 4: 4.23082486372574\n",
      "Feature 70: -3.962791561217739\n",
      "Feature 19: -3.0943645336393315\n",
      "Feature 27: -3.048962855346275\n",
      "Feature 49: -2.821501485927969\n",
      "Feature 25: -2.80362229513657\n",
      "Feature 23: -2.7836791920330093\n",
      "Feature 75: 1.741445073252944\n",
      "Feature 22: -1.5216484040881255\n",
      "Feature 26: 1.5048518051592765\n",
      "Feature 67: -1.2174039376712675\n",
      "Feature 18: -1.1408173040501595\n",
      "Feature 20: -1.1388119718538778\n",
      "Feature 64: -0.8791950995003504\n",
      "Feature 7: 0.5869427081207523\n",
      "Feature 63: -0.46564871018995735\n",
      "Feature 15: 0.43415042751425714\n",
      "Feature 0: 0.4303669683291209\n",
      "Feature 71: 0.37554172418786447\n",
      "Feature 24: -0.29965339508914113\n",
      "Feature 5: 0.28096628747582053\n",
      "Feature 6: 0.1349536636321873\n",
      "Feature 1: -0.06829597941304205\n",
      "Feature 2: -0.041164484107814925\n",
      "Feature 3: -0.04046154538558072\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have X_train and y_train defined for training data\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Fit the Linear Regression model to the training data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature coefficients\n",
    "coefficients = lr_model.coef_\n",
    "\n",
    "# Create a list of feature names or indices paired with their coefficients\n",
    "feature_coefficients = list(zip(range(X_train.shape[1]), coefficients))\n",
    "\n",
    "# Sort the features based on absolute coefficient values in descending order\n",
    "feature_coefficients.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Print the ranked feature coefficients\n",
    "print(\"Feature Coefficients:\")\n",
    "for feature_index, coefficient in feature_coefficients:\n",
    "    print(f\"Feature {feature_index}: {coefficient}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter optimalisatie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | fit_in... |\n",
      "-------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.9777   \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.1801   \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.8115   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.07396  \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.5982   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.0002154\u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.3309   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.5086   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.9998   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.9999   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m6.875e-05\u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.9018   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.6319   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.00012  \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.0001581\u001b[0m |\n",
      "=====================================\n",
      "RMSE: 29.62991618359718\n",
      "MSE: 877.9319330469941\n",
      "MAE: 13.486674234523353\n",
      "AED: [1.15446157 1.79205502 5.49922217 ... 7.33235646 4.91178365 1.91482707]\n",
      "R2: 0.017581490201935224\n",
      "Adjusted R2: -0.03416011393927598\n"
     ]
    }
   ],
   "source": [
    "# Define the MLR model evaluation function using cross-validation\n",
    "def evaluate_mlr_model(fit_intercept):\n",
    "    # Convert fit_intercept to a boolean value\n",
    "    fit_intercept = bool(fit_intercept)\n",
    "    \n",
    "    # Create and configure the MLR model\n",
    "    model = LinearRegression(fit_intercept=fit_intercept)\n",
    "    \n",
    "    # Perform cross-validation on the training data\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Return the negative mean squared error (Bayesian Optimization maximizes the objective)\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Define the parameter ranges for Bayesian Optimization\n",
    "params_ranges = {\n",
    "    'fit_intercept': (0, 1)\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "mlr_bo = BayesianOptimization(f=evaluate_mlr_model, pbounds=params_ranges)\n",
    "mlr_bo.maximize(n_iter=10, init_points=5)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = mlr_bo.max['params']\n",
    "best_fit_intercept = bool(best_params['fit_intercept'])\n",
    "\n",
    "# Create the best MLR model with the tuned hyperparameters\n",
    "best_model_mlr = LinearRegression(fit_intercept=best_fit_intercept)\n",
    "\n",
    "# Fit the best model to the training data\n",
    "best_model_mlr.fit(X_train, y_train)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "y_pred = best_model_mlr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "aed = np.abs(y_test.mean() - y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = len(X_test)\n",
    "k = X_test.shape[1]\n",
    "r2_adj = 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"AED:\", aed)\n",
    "print(\"R2:\", r2)\n",
    "print(\"Adjusted R2:\", r2_adj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Feature Selection here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have X_train and y_train defined for training data\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVR(kernel='linear')  # Replace 'rbf' with your desired kernel\n",
    "\n",
    "# Fit the SVM model to the training data\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "model.n_jobs = -1\n",
    "\n",
    "# Compute permutation importances\n",
    "result = permutation_importance(svm_model, X_train, y_train, n_repeats=10, random_state=42)\n",
    "\n",
    "# Get feature importances\n",
    "importances = result.importances_mean\n",
    "\n",
    "# Create a list of feature names or indices paired with their importances\n",
    "feature_importances = list(zip(range(X_train.shape[1]), importances))\n",
    "\n",
    "# Sort the features based on importance in descending order\n",
    "feature_importances.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "# Print the ranked feature importances\n",
    "print(\"Feature Importances:\")\n",
    "for feature_index, importance in feature_importances:\n",
    "    print(f\"Feature {feature_index}: {importance}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter optimalisatie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SVM model evaluation function using cross-validation\n",
    "def evaluate_svm_model(C, epsilon, gamma):\n",
    "    # Create and configure the SVM model\n",
    "    model = SVR(C=C, epsilon=epsilon, gamma=gamma)\n",
    "    \n",
    "    # Perform cross-validation on the training data\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Return the negative mean squared error (Bayesian Optimization maximizes the objective)\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Define the parameter ranges for Bayesian Optimization\n",
    "params_ranges = {\n",
    "    'C': (0.1, 10),\n",
    "    'epsilon': (0.01, 1),\n",
    "    'gamma': (0.001, 0.1)\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "svm_bo = BayesianOptimization(f=evaluate_svm_model, pbounds=params_ranges)\n",
    "svm_bo.maximize(n_iter=10, init_points=5)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = svm_bo.max['params']\n",
    "best_C = best_params['C']\n",
    "best_epsilon = best_params['epsilon']\n",
    "best_gamma = best_params['gamma']\n",
    "\n",
    "# Create the best SVM model with the tuned hyperparameters\n",
    "best_model_svm = SVR(C=best_C, epsilon=best_epsilon, gamma=best_gamma)\n",
    "\n",
    "# Fit the best model to the training data\n",
    "best_model_svm.fit(X_train, y_train)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "y_pred = best_model_svm.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "aed = np.abs(y_test.mean() - y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = len(X_test)\n",
    "k = X_test.shape[1]\n",
    "r2_adj = 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"AED:\", aed)\n",
    "print(\"R2:\", r2)\n",
    "print(\"Adjusted R2:\", r2_adj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have X_train and y_train defined for training data\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Fit the Random Forest model to the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Create a list of feature names or indices paired with their importances\n",
    "feature_importances = list(zip(range(X_train.shape[1]), importances))\n",
    "\n",
    "# Sort the features based on importance in descending order\n",
    "feature_importances.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the ranked feature importances\n",
    "print(\"Feature Importances:\")\n",
    "for feature_index, importance in feature_importances:\n",
    "    print(f\"Feature {feature_index}: {importance}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter optimalisatie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ranges = {\n",
    "    'n_estimators': (10, 100),\n",
    "    'max_depth': (1, 20),\n",
    "    'min_samples_leaf': (1, 10),\n",
    "    'min_weight_fraction_leaf': (0.0, 0.5),\n",
    "    'max_features': (0.1, 1),\n",
    "    'max_leaf_nodes': (10, 100)\n",
    "}\n",
    "\n",
    "# Example usage with Random Forest\n",
    "model = RandomForestRegressor\n",
    "dt_bo = BayesianOptimization(f=lambda n_estimators, max_depth, min_samples_leaf, min_weight_fraction_leaf,\n",
    "                                    max_features, max_leaf_nodes: bo_params_generic(model, {\n",
    "                                        'n_estimators': int(round(n_estimators)),\n",
    "                                        'max_depth': int(round(max_depth)),\n",
    "                                        'min_samples_leaf': round(min_samples_leaf),\n",
    "                                        'min_weight_fraction_leaf': min_weight_fraction_leaf,\n",
    "                                        'max_features': max_features,\n",
    "                                        'max_leaf_nodes': int(round(max_leaf_nodes))\n",
    "                                    }, X_train, y_train),\n",
    "                             pbounds=params_ranges)\n",
    "results = dt_bo.maximize(n_iter=5, init_points=20)\n",
    "params = dt_bo.max['params']\n",
    "\n",
    "# Creating a model with the best hyperparameters\n",
    "best_model_random_forest = model(\n",
    "    n_estimators=int(round(params['n_estimators'])),\n",
    "    max_depth=int(round(params['max_depth'])),\n",
    "    min_samples_leaf=round(params['min_samples_leaf']),\n",
    "    min_weight_fraction_leaf=params['min_weight_fraction_leaf'],\n",
    "    max_features=params['max_features'],\n",
    "    max_leaf_nodes=int(round(params['max_leaf_nodes']))\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "best_model_random_forest.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_pred = best_model_random_forest.predict(X_test)\n",
    "\n",
    "mse_scores = mean_squared_error(y_test, y_pred)\n",
    "mae_scores = mean_absolute_error(y_test, y_pred)\n",
    "aed_scores = np.abs(y_test.mean() - y_pred)\n",
    "r2_scores = r2_score(y_test, y_pred)\n",
    "\n",
    "n = len(X_test)\n",
    "k = X_test.shape[1]\n",
    "r2_adj_scores = 1 - (1 - r2_scores) * ((n - 1) / (n - k - 1))\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"MSE:\", mse_scores)\n",
    "print(\"MAE:\", mae_scores)\n",
    "print(\"AED:\", aed_scores)\n",
    "print(\"R2:\", r2_scores)\n",
    "print(\"Adjusted R2:\", r2_adj_scores)\n",
    "print(\"RMSE:\", rmse_scores)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have X and y defined for the dataset\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the neural network regressor\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(10, 10))  # Adjust the architecture as needed\n",
    "\n",
    "# Fit the neural network model to the training data\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Perform feature selection using Recursive Feature Elimination (RFE)\n",
    "selector = RFE(estimator=nn_model, n_features_to_select=10)  # Adjust n_features_to_select as needed\n",
    "selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Transform the training and testing sets to keep only the selected features\n",
    "X_train_selected = selector.transform(X_train_scaled)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Print the selected feature support\n",
    "selected_support = selector.support_\n",
    "print(\"Selected Feature Support:\")\n",
    "print(selected_support)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter optimalisatie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ranges = {\n",
    "    'hidden_layer_sizes': (10, 100),\n",
    "    'alpha': (0.0001, 0.1),\n",
    "    'learning_rate_init': (0.001, 0.1),\n",
    "    'max_iter': (100, 1000),\n",
    "}\n",
    "\n",
    "# Example usage with Neural Network\n",
    "model = MLPRegressor\n",
    "dt_bo = BayesianOptimization(f=lambda hidden_layer_sizes, alpha, learning_rate_init, max_iter:\n",
    "                                    bo_params_generic(model, {\n",
    "                                        'hidden_layer_sizes': (int(round(hidden_layer_sizes)),),\n",
    "                                        'alpha': alpha,\n",
    "                                        'learning_rate_init': learning_rate_init,\n",
    "                                        'max_iter': int(round(max_iter))\n",
    "                                    }, X_train, y_train),\n",
    "                             pbounds=params_ranges)\n",
    "\n",
    "results = dt_bo.maximize(n_iter=5, init_points=20)\n",
    "params = dt_bo.max['params']\n",
    "\n",
    "# Creating a model with the best hyperparameters\n",
    "best_model_neural_network = model(\n",
    "    hidden_layer_sizes=(int(round(params['hidden_layer_sizes'])),),\n",
    "    alpha=params['alpha'],\n",
    "    learning_rate_init=params['learning_rate_init'],\n",
    "    max_iter=int(round(params['max_iter']))\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "best_model_neural_network.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "aed = np.abs(y_test.mean() - y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = len(X_test)\n",
    "k = X_test.shape[1]\n",
    "r2_adj = 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"AED:\", aed)\n",
    "print(\"R2:\", r2)\n",
    "print(\"Adjusted R2:\", r2_adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append model to list\n",
    "all_models['Random forest'] = best_model_random_forest\n",
    "all_models['SVM'] = best_model_svm\n",
    "all_models['Neural Network'] = best_model_neural_network\n",
    "all_models['MLR']= best_model_mlr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting the bar chart"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metric labels\n",
    "metric_labels = ['RMSE', 'MSE', 'MAE', 'AED', 'R2', 'Adjusted R2']\n",
    "\n",
    "# Calculate evaluation metrics using cross-validation for each model\n",
    "metrics = {\n",
    "    'RMSE': lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    'MSE': mean_squared_error,\n",
    "    'MAE': mean_absolute_error,\n",
    "    'AED': lambda y_true, y_pred: np.abs(np.mean(y_true) - y_pred),\n",
    "    'R2': r2_score,\n",
    "    'Adjusted R2': lambda y_true, y_pred: 1 - ((1 - r2_score(y_true, y_pred)) * (len(y_true) - 1) / (len(y_true) - X_train.shape[1] - 1))\n",
    "}\n",
    "\n",
    "model_names = ['Random Forest', 'SVM', 'Neural Network', 'MLR']\n",
    "\n",
    "models = {\n",
    "    'Random Forest': best_model_random_forest,\n",
    "    'SVM': best_model_svm,\n",
    "    'Neural Network': best_model_neural_network,\n",
    "    'MLR': best_model_mlr\n",
    "}\n",
    "\n",
    "metric_scores = {metric: [] for metric in metric_labels}\n",
    "\n",
    "for model_name in model_names:\n",
    "    model = models[model_name]\n",
    "    y_pred = cross_val_predict(model, X_train, y_train, cv=5)\n",
    "    for metric in metric_labels:\n",
    "        metric_scores[metric].append(metrics[metric](y_train, y_pred))\n",
    "\n",
    "# Plotting the bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "for metric in metric_labels:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=model_names,\n",
    "        y=metric_scores[metric],\n",
    "        name=metric\n",
    "    ))\n",
    "\n",
    "# Updating the layout\n",
    "fig.update_layout(\n",
    "    title='Evaluation Metrics Comparison',\n",
    "    xaxis_title='Models',\n",
    "    yaxis_title='Scores',\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metric labels\n",
    "metric_labels = ['RMSE', 'MSE', 'MAE', 'AED', 'R2', 'Adjusted R2']\n",
    "\n",
    "# Calculate evaluation metrics using cross-validation for each model\n",
    "metrics = {\n",
    "    'RMSE': lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    'MSE': mean_squared_error,\n",
    "    'MAE': mean_absolute_error,\n",
    "    'AED': lambda y_true, y_pred: np.abs(np.mean(y_true) - y_pred),\n",
    "    'R2': r2_score,\n",
    "    'Adjusted R2': lambda y_true, y_pred: 1 - ((1 - r2_score(y_true, y_pred)) * (len(y_true) - 1) / (len(y_true) - X_train.shape[1] - 1))\n",
    "}\n",
    "\n",
    "model_names = ['Random Forest', 'SVM', 'Neural Network', 'MLR']\n",
    "\n",
    "models = {\n",
    "    'Random Forest': best_model_random_forest,\n",
    "    'SVM': best_model_svm,\n",
    "    'Neural Network': best_model_neural_network,\n",
    "    'MLR': best_model_mlr\n",
    "}\n",
    "\n",
    "# Train each model on the training data and predict the test data\n",
    "predictions = {}\n",
    "for model_name in model_names:\n",
    "    model = models[model_name]\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    predictions[model_name] = model.predict(X_test)  # Predict the test data\n",
    "\n",
    "# Calculate each metric for each model's predictions\n",
    "metric_scores = {metric: [] for metric in metric_labels}\n",
    "for model_name in model_names:\n",
    "    y_pred = predictions[model_name]\n",
    "    for metric in metric_labels:\n",
    "        metric_scores[metric].append(metrics[metric](y_test, y_pred))  # Use the test data here\n",
    "\n",
    "# Plotting the bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "for metric in metric_labels:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=model_names,\n",
    "        y=metric_scores[metric],\n",
    "        name=metric\n",
    "    ))\n",
    "\n",
    "# Updating the layout\n",
    "fig.update_layout(\n",
    "    title='Evaluation Metrics Comparison',\n",
    "    xaxis_title='Models',\n",
    "    yaxis_title='Scores',\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
