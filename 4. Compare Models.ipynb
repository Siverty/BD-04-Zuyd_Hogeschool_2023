{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing all libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from bayes_opt import BayesianOptimization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disable all warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Enable warnings again\n",
    "## warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finished = pd.read_csv(\"data_finish_prep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verschil_Lengte</th>\n",
       "      <th>verschil_Gewicht</th>\n",
       "      <th>verschil_6 MWT</th>\n",
       "      <th>verschil_TUG</th>\n",
       "      <th>verschil_BMI</th>\n",
       "      <th>verschil_Conditie</th>\n",
       "      <th>verschil_Lenigheid</th>\n",
       "      <th>verschil_Knijpkracht</th>\n",
       "      <th>NederlandseAntillenEnAruba</th>\n",
       "      <th>GeboorteRelatief</th>\n",
       "      <th>...</th>\n",
       "      <th>Ondergewicht</th>\n",
       "      <th>MatigOvergewicht</th>\n",
       "      <th>ErnstigOvergewichtObesitas</th>\n",
       "      <th>VoldoetAanBeweegrichtlijn</th>\n",
       "      <th>Mantelzorger</th>\n",
       "      <th>ZwaarBelasteMantelzorgers</th>\n",
       "      <th>UrenMantelzorgPerWeek</th>\n",
       "      <th>Rokers</th>\n",
       "      <th>VoldoetAanRichtlijnAlcoholgebruik</th>\n",
       "      <th>OvermatigDrinker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>-0.906068</td>\n",
       "      <td>-0.125200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.8</td>\n",
       "      <td>-0.063003</td>\n",
       "      <td>-0.933187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570059</td>\n",
       "      <td>0.531251</td>\n",
       "      <td>0.934008</td>\n",
       "      <td>-0.796811</td>\n",
       "      <td>0.94649</td>\n",
       "      <td>-0.053768</td>\n",
       "      <td>-0.233017</td>\n",
       "      <td>1.074978</td>\n",
       "      <td>0.932579</td>\n",
       "      <td>-0.702505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>-104.0</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>-3.133140</td>\n",
       "      <td>-0.384503</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>-0.063003</td>\n",
       "      <td>-0.933187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570059</td>\n",
       "      <td>0.531251</td>\n",
       "      <td>0.934008</td>\n",
       "      <td>-0.796811</td>\n",
       "      <td>0.94649</td>\n",
       "      <td>-0.053768</td>\n",
       "      <td>-0.233017</td>\n",
       "      <td>1.074978</td>\n",
       "      <td>0.932579</td>\n",
       "      <td>-0.702505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>-2.143719</td>\n",
       "      <td>0.080729</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-0.063003</td>\n",
       "      <td>-0.933187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570059</td>\n",
       "      <td>0.531251</td>\n",
       "      <td>0.934008</td>\n",
       "      <td>-0.796811</td>\n",
       "      <td>0.94649</td>\n",
       "      <td>-0.053768</td>\n",
       "      <td>-0.233017</td>\n",
       "      <td>1.074978</td>\n",
       "      <td>0.932579</td>\n",
       "      <td>-0.702505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-2.07</td>\n",
       "      <td>-0.521359</td>\n",
       "      <td>0.020537</td>\n",
       "      <td>4.25</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-0.063003</td>\n",
       "      <td>-0.933187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570059</td>\n",
       "      <td>0.531251</td>\n",
       "      <td>0.934008</td>\n",
       "      <td>-0.796811</td>\n",
       "      <td>0.94649</td>\n",
       "      <td>-0.053768</td>\n",
       "      <td>-0.233017</td>\n",
       "      <td>1.074978</td>\n",
       "      <td>0.932579</td>\n",
       "      <td>-0.702505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.221264</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-0.063003</td>\n",
       "      <td>-0.933187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570059</td>\n",
       "      <td>0.531251</td>\n",
       "      <td>0.934008</td>\n",
       "      <td>-0.796811</td>\n",
       "      <td>0.94649</td>\n",
       "      <td>-0.053768</td>\n",
       "      <td>-0.233017</td>\n",
       "      <td>1.074978</td>\n",
       "      <td>0.932579</td>\n",
       "      <td>-0.702505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   verschil_Lengte  verschil_Gewicht  verschil_6 MWT  verschil_TUG  \\\n",
       "0              0.0              -2.3           -52.0          2.94   \n",
       "1              0.0              -7.2          -104.0         -2.43   \n",
       "2              1.0              -4.9            63.0         -1.92   \n",
       "3              0.0              -1.3            23.0         -2.07   \n",
       "4              0.0               2.0           126.0          0.69   \n",
       "\n",
       "   verschil_BMI  verschil_Conditie  verschil_Lenigheid  verschil_Knijpkracht  \\\n",
       "0     -0.906068          -0.125200                 NaN                  30.8   \n",
       "1     -3.133140          -0.384503               -4.00                  11.5   \n",
       "2     -2.143719           0.080729                7.50                   2.7   \n",
       "3     -0.521359           0.020537                4.25                  -1.7   \n",
       "4      0.800000           0.221264               -2.50                   5.5   \n",
       "\n",
       "   NederlandseAntillenEnAruba  GeboorteRelatief  ...  Ondergewicht  \\\n",
       "0                   -0.063003         -0.933187  ...      0.570059   \n",
       "1                   -0.063003         -0.933187  ...      0.570059   \n",
       "2                   -0.063003         -0.933187  ...      0.570059   \n",
       "3                   -0.063003         -0.933187  ...      0.570059   \n",
       "4                   -0.063003         -0.933187  ...      0.570059   \n",
       "\n",
       "   MatigOvergewicht  ErnstigOvergewichtObesitas  VoldoetAanBeweegrichtlijn  \\\n",
       "0          0.531251                    0.934008                  -0.796811   \n",
       "1          0.531251                    0.934008                  -0.796811   \n",
       "2          0.531251                    0.934008                  -0.796811   \n",
       "3          0.531251                    0.934008                  -0.796811   \n",
       "4          0.531251                    0.934008                  -0.796811   \n",
       "\n",
       "   Mantelzorger  ZwaarBelasteMantelzorgers  UrenMantelzorgPerWeek    Rokers  \\\n",
       "0       0.94649                  -0.053768              -0.233017  1.074978   \n",
       "1       0.94649                  -0.053768              -0.233017  1.074978   \n",
       "2       0.94649                  -0.053768              -0.233017  1.074978   \n",
       "3       0.94649                  -0.053768              -0.233017  1.074978   \n",
       "4       0.94649                  -0.053768              -0.233017  1.074978   \n",
       "\n",
       "   VoldoetAanRichtlijnAlcoholgebruik  OvermatigDrinker  \n",
       "0                           0.932579         -0.702505  \n",
       "1                           0.932579         -0.702505  \n",
       "2                           0.932579         -0.702505  \n",
       "3                           0.932579         -0.702505  \n",
       "4                           0.932579         -0.702505  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_finished.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finished.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dataframes for each dependent variable\n",
    "\n",
    "# Fixing 6MWT column name\n",
    "df_finished = df_finished.rename(columns={\"verschil_6 MWT\": \"verschil_6_MWT\"})\n",
    "\n",
    "# Verschil in gewicht\n",
    "df_target_gewicht = df_finished[\"verschil_Gewicht\"]\n",
    "df_test_Gewicht = df_finished.drop([\"verschil_Gewicht\"], axis=1)\n",
    "\n",
    "# Verschil in 6MWT\n",
    "df_target_6_MWT = df_finished[\"verschil_6_MWT\"]\n",
    "df_test_6_MWT = df_finished.drop([\"verschil_6_MWT\"], axis=1)\n",
    "\n",
    "# Verschil in TUG\n",
    "df_target_TUG = df_finished[\"verschil_TUG\"]\n",
    "df_test_TUG = df_finished.drop([\"verschil_TUG\"], axis=1)\n",
    "\n",
    "\n",
    "# Verschil in BMI\n",
    "df_target_BMI = df_finished[\"verschil_BMI\"]\n",
    "df_test_BMI = df_finished.drop([\"verschil_BMI\"], axis=1)\n",
    "\n",
    "\n",
    "# Verschil in Conditie\n",
    "df_target_Conditie = df_finished[\"verschil_Conditie\"]\n",
    "df_test_Conditie = df_finished.drop([\"verschil_Conditie\"], axis=1)\n",
    "\n",
    "\n",
    "# Verschil in Lenigheid\n",
    "df_target_Lenigheid = df_finished[\"verschil_Lenigheid\"]\n",
    "df_test_Lenigheid = df_finished.drop([\"verschil_Lenigheid\"], axis=1)\n",
    "\n",
    "\n",
    "# Verschil in Knijpkracht\n",
    "df_target_Knijpkracht = df_finished[\"verschil_Knijpkracht\"]\n",
    "df_test_Knijpkracht = df_finished.drop([\"verschil_Knijpkracht\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1099\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows\n",
    "num_rows = df_finished.shape[0]\n",
    "\n",
    "# Print the number of rows\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for Verschil in Gewicht\n",
    "X_train_Gewicht, X_test_Gewicht, y_train_Gewicht, y_test_Gewicht = train_test_split(\n",
    "    df_test_Gewicht, df_target_gewicht, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split data for Verschil in 6MWT\n",
    "X_train_6_MWT, X_test_6_MWT, y_train_6_MWT, y_test_6_MWT = train_test_split(\n",
    "    df_test_6_MWT, df_target_6_MWT, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split data for Verschil in TUG\n",
    "X_train_TUG, X_test_TUG, y_train_TUG, y_test_TUG = train_test_split(\n",
    "    df_test_TUG, df_target_TUG, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split data for Verschil in BMI\n",
    "X_train_BMI, X_test_BMI, y_train_BMI, y_test_BMI = train_test_split(\n",
    "    df_test_BMI, df_target_BMI, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split data for Verschil in Conditie\n",
    "X_train_Conditie, X_test_Conditie, y_train_Conditie, y_test_Conditie = train_test_split(\n",
    "    df_test_Conditie, df_target_Conditie, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split data for Verschil in Lenigheid\n",
    "(\n",
    "    X_train_Lenigheid,\n",
    "    X_test_Lenigheid,\n",
    "    y_train_Lenigheid,\n",
    "    y_test_Lenigheid,\n",
    ") = train_test_split(\n",
    "    df_test_Lenigheid, df_target_Lenigheid, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split data for Verschil in Knijpkracht\n",
    "(\n",
    "    X_train_Knijpkracht,\n",
    "    X_test_Knijpkracht,\n",
    "    y_train_Knijpkracht,\n",
    "    y_test_Knijpkracht,\n",
    ") = train_test_split(\n",
    "    df_test_Knijpkracht, df_target_Knijpkracht, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# # Split data into training and testing sets\n",
    "# train_ratio = 0.8\n",
    "# train_size = int(train_ratio * num_rows)\n",
    "\n",
    "# X_train = X[:train_size]\n",
    "# y_train = y[:train_size]\n",
    "\n",
    "# # Test data\n",
    "# X_test = X[train_size:]\n",
    "# y_test = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the feature variables into X\n",
    "X = np.concatenate(\n",
    "    (\n",
    "        X_train_Gewicht,\n",
    "        X_train_6_MWT,\n",
    "        X_train_TUG,\n",
    "        X_train_BMI,\n",
    "        X_train_Conditie,\n",
    "        X_train_Lenigheid,\n",
    "        X_train_Knijpkracht,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Concatenate the target variables into y\n",
    "y = np.concatenate(\n",
    "    (\n",
    "        y_train_Gewicht,\n",
    "        y_train_6_MWT,\n",
    "        y_train_TUG,\n",
    "        y_train_BMI,\n",
    "        y_train_Conditie,\n",
    "        y_train_Lenigheid,\n",
    "        y_train_Knijpkracht,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Test data\n",
    "X_test = np.concatenate(\n",
    "    (\n",
    "        X_test_Gewicht,\n",
    "        X_test_6_MWT,\n",
    "        X_test_TUG,\n",
    "        X_test_BMI,\n",
    "        X_test_Conditie,\n",
    "        X_test_Lenigheid,\n",
    "        X_test_Knijpkracht,\n",
    "    )\n",
    ")\n",
    "y_test = np.concatenate(\n",
    "    (\n",
    "        y_test_Gewicht,\n",
    "        y_test_6_MWT,\n",
    "        y_test_TUG,\n",
    "        y_test_BMI,\n",
    "        y_test_Conditie,\n",
    "        y_test_Lenigheid,\n",
    "        y_test_Knijpkracht,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(X))\n",
    "\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bo_params_generic(model, params, X_train, y_train):\n",
    "    # Create the model instance with the specified parameters\n",
    "    regressor = model(**params)\n",
    "\n",
    "    # Assuming you have X_train, y_train defined for regression\n",
    "    scores = cross_val_score(\n",
    "        regressor, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\"\n",
    "    )\n",
    "    return -scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = dt_bo.maximize(n_iter=5, init_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Coefficients:\n",
      "Feature 50: 148.18228651982133\n",
      "Feature 60: -147.53045902153002\n",
      "Feature 33: 77.98641807699985\n",
      "Feature 54: 66.6448127066419\n",
      "Feature 34: 63.29586560353903\n",
      "Feature 59: -53.950473011576264\n",
      "Feature 32: 53.229963200358185\n",
      "Feature 35: -49.14526062800492\n",
      "Feature 30: -29.928311411819603\n",
      "Feature 58: 28.649953909340002\n",
      "Feature 45: 28.581497333744974\n",
      "Feature 55: 28.36333581776917\n",
      "Feature 65: 27.48371236077007\n",
      "Feature 31: -27.01639096894545\n",
      "Feature 57: 25.941948982519058\n",
      "Feature 56: 25.643573112531143\n",
      "Feature 29: -25.02547400814238\n",
      "Feature 9: -17.629037971976828\n",
      "Feature 14: 16.966229886396405\n",
      "Feature 38: -15.533730125218412\n",
      "Feature 47: -15.412505845506297\n",
      "Feature 40: 14.584594837611832\n",
      "Feature 51: -14.531648801348645\n",
      "Feature 28: 13.929463847988018\n",
      "Feature 74: -13.794527656437573\n",
      "Feature 62: -13.59782701125398\n",
      "Feature 52: -13.387682983132803\n",
      "Feature 73: -12.802850456650564\n",
      "Feature 46: 12.693166874416104\n",
      "Feature 48: 11.940274169104939\n",
      "Feature 43: 11.290722082790644\n",
      "Feature 37: 11.275013920111197\n",
      "Feature 66: 11.101167298108447\n",
      "Feature 11: -11.075227117256912\n",
      "Feature 42: 9.809978689802804\n",
      "Feature 53: -8.78469092877564\n",
      "Feature 68: 8.316605446616443\n",
      "Feature 44: 8.232295303501493\n",
      "Feature 76: -8.155340109676679\n",
      "Feature 36: 7.344378811613651\n",
      "Feature 10: 7.271823841973317\n",
      "Feature 12: 6.7657842437204705\n",
      "Feature 8: 6.7043529495675696\n",
      "Feature 72: 6.578335846650877\n",
      "Feature 16: -6.407008381319411\n",
      "Feature 39: -6.337753108246024\n",
      "Feature 13: -6.117016764256453\n",
      "Feature 21: 6.012100254529593\n",
      "Feature 41: 5.266257790191194\n",
      "Feature 61: 5.171660577991625\n",
      "Feature 17: 4.832599282238247\n",
      "Feature 69: -4.362707863674926\n",
      "Feature 4: 4.23082486372574\n",
      "Feature 70: -3.962791561217739\n",
      "Feature 19: -3.0943645336393315\n",
      "Feature 27: -3.048962855346275\n",
      "Feature 49: -2.821501485927969\n",
      "Feature 25: -2.80362229513657\n",
      "Feature 23: -2.7836791920330093\n",
      "Feature 75: 1.741445073252944\n",
      "Feature 22: -1.5216484040881255\n",
      "Feature 26: 1.5048518051592765\n",
      "Feature 67: -1.2174039376712675\n",
      "Feature 18: -1.1408173040501595\n",
      "Feature 20: -1.1388119718538778\n",
      "Feature 64: -0.8791950995003504\n",
      "Feature 7: 0.5869427081207523\n",
      "Feature 63: -0.46564871018995735\n",
      "Feature 15: 0.43415042751425714\n",
      "Feature 0: 0.4303669683291209\n",
      "Feature 71: 0.37554172418786447\n",
      "Feature 24: -0.29965339508914113\n",
      "Feature 5: 0.28096628747582053\n",
      "Feature 6: 0.1349536636321873\n",
      "Feature 1: -0.06829597941304205\n",
      "Feature 2: -0.041164484107814925\n",
      "Feature 3: -0.04046154538558072\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have X_train and y_train defined for training data\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Fit the Linear Regression model to the training data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature coefficients\n",
    "coefficients = lr_model.coef_\n",
    "\n",
    "# Create a list of feature names or indices paired with their coefficients\n",
    "feature_coefficients = list(zip(range(X_train.shape[1]), coefficients))\n",
    "\n",
    "# Sort the features based on absolute coefficient values in descending order\n",
    "feature_coefficients.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Print the ranked feature coefficients\n",
    "print(\"Feature Coefficients:\")\n",
    "for feature_index, coefficient in feature_coefficients:\n",
    "    print(f\"Feature {feature_index}: {coefficient}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter optimalisatie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | fit_in... |\n",
      "-------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.7268   \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.5064   \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.3515   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.5671   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.3513   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m1.255e-05\u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.5974   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.9345   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.0001965\u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m5.062e-05\u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.7438   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.8658   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.0001564\u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-1.451e+0\u001b[0m | \u001b[0m0.9999   \u001b[0m |\n",
      "=====================================\n",
      "RMSE: 29.62991618359718\n",
      "MSE: 877.9319330469941\n",
      "MAE: 13.486674234523353\n",
      "AED: [1.15446157 1.79205502 5.49922217 ... 7.33235646 4.91178365 1.91482707]\n",
      "R2: 0.017581490201935224\n",
      "Adjusted R2: -0.03416011393927598\n"
     ]
    }
   ],
   "source": [
    "# Define the MLR model evaluation function using cross-validation\n",
    "def evaluate_mlr_model(fit_intercept):\n",
    "    # Convert fit_intercept to a boolean value\n",
    "    fit_intercept = bool(fit_intercept)\n",
    "\n",
    "    # Create and configure the MLR model\n",
    "    model = LinearRegression(fit_intercept=fit_intercept)\n",
    "\n",
    "    # Perform cross-validation on the training data\n",
    "    scores = cross_val_score(\n",
    "        model, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    "\n",
    "    # Return the negative mean squared error (Bayesian Optimization maximizes the objective)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Define the parameter ranges for Bayesian Optimization\n",
    "params_ranges = {\"fit_intercept\": (0, 1)}\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "mlr_bo = BayesianOptimization(f=evaluate_mlr_model, pbounds=params_ranges)\n",
    "mlr_bo.maximize(n_iter=10, init_points=5)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = mlr_bo.max[\"params\"]\n",
    "best_fit_intercept = bool(best_params[\"fit_intercept\"])\n",
    "\n",
    "# Create the best MLR model with the tuned hyperparameters\n",
    "best_model_mlr = LinearRegression(fit_intercept=best_fit_intercept)\n",
    "\n",
    "# Fit the best model to the training data\n",
    "best_model_mlr.fit(X_train, y_train)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "y_pred = best_model_mlr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "aed = np.abs(y_test.mean() - y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = len(X_test)\n",
    "k = X_test.shape[1]\n",
    "r2_adj = 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"AED:\", aed)\n",
    "print(\"R2:\", r2)\n",
    "print(\"Adjusted R2:\", r2_adj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Feature Selection here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "Feature 1: 0.0004554964515670834\n",
      "Feature 59: 0.00010437783791610311\n",
      "Feature 56: 8.310404113678337e-05\n",
      "Feature 52: 7.974914819208756e-05\n",
      "Feature 32: 6.324607998213772e-05\n",
      "Feature 42: 5.6654540048017844e-05\n",
      "Feature 37: 3.783495078115706e-05\n",
      "Feature 61: 2.053544237645699e-05\n",
      "Feature 57: 2.0302851181241975e-05\n",
      "Feature 6: 1.9389145151849084e-05\n",
      "Feature 43: 1.4835921667222251e-05\n",
      "Feature 67: 1.4676821561709908e-05\n",
      "Feature 53: 1.4382116639510834e-05\n",
      "Feature 44: 1.4281660481607616e-05\n",
      "Feature 76: 1.0258771337001704e-05\n",
      "Feature 14: 1.0245770403516375e-05\n",
      "Feature 54: 9.886862436414567e-06\n",
      "Feature 45: 9.84627382378811e-06\n",
      "Feature 27: 8.42623237664597e-06\n",
      "Feature 17: 6.518040989789142e-06\n",
      "Feature 21: 6.3958433441868575e-06\n",
      "Feature 31: 4.82860372192917e-06\n",
      "Feature 16: 4.393296858351548e-06\n",
      "Feature 11: 3.6815539209644755e-06\n",
      "Feature 48: 3.2650904516762225e-06\n",
      "Feature 70: 2.489181138720653e-06\n",
      "Feature 63: 2.4263740126206913e-06\n",
      "Feature 36: 2.2326852141096863e-06\n",
      "Feature 73: 1.5565423883368013e-06\n",
      "Feature 49: 9.130439900806309e-07\n",
      "Feature 0: 8.268330157434889e-07\n",
      "Feature 10: 7.957800472357945e-07\n",
      "Feature 74: 7.867583070142459e-07\n",
      "Feature 46: 5.919136683907311e-07\n",
      "Feature 15: 5.057626273785587e-07\n",
      "Feature 12: 4.420601057653073e-07\n",
      "Feature 24: 2.551675525097608e-07\n",
      "Feature 19: 6.396967926480812e-08\n",
      "Feature 25: 1.4238507195507567e-08\n",
      "Feature 22: -6.395741112275032e-08\n",
      "Feature 7: -8.584444226578114e-08\n",
      "Feature 23: -1.3618367433743117e-07\n",
      "Feature 18: -3.2550700979072644e-07\n",
      "Feature 35: -5.101339784818748e-07\n",
      "Feature 47: -5.76113944861234e-07\n",
      "Feature 72: -6.435528003168045e-07\n",
      "Feature 38: -7.644300418441219e-07\n",
      "Feature 41: -8.068227166813102e-07\n",
      "Feature 75: -1.1170169158303266e-06\n",
      "Feature 66: -1.5494832746432153e-06\n",
      "Feature 39: -2.6203211386688354e-06\n",
      "Feature 69: -2.8257643419848933e-06\n",
      "Feature 29: -4.261107248515472e-06\n",
      "Feature 9: -4.303922819937078e-06\n",
      "Feature 65: -4.574093027343018e-06\n",
      "Feature 20: -4.609877298267229e-06\n",
      "Feature 8: -5.302387577499346e-06\n",
      "Feature 28: -5.366702329201445e-06\n",
      "Feature 71: -5.388636746550546e-06\n",
      "Feature 60: -5.493205035134174e-06\n",
      "Feature 13: -6.493562517251306e-06\n",
      "Feature 55: -9.275755957816045e-06\n",
      "Feature 68: -1.0491859696704076e-05\n",
      "Feature 40: -1.0605029621646445e-05\n",
      "Feature 34: -1.064330696243232e-05\n",
      "Feature 64: -1.231310679030706e-05\n",
      "Feature 26: -1.2665591359573014e-05\n",
      "Feature 30: -1.808148236714935e-05\n",
      "Feature 58: -2.4331778565489515e-05\n",
      "Feature 50: -2.5020192867719616e-05\n",
      "Feature 51: -4.511651281746687e-05\n",
      "Feature 33: -6.579994969666548e-05\n",
      "Feature 3: -7.848878975860173e-05\n",
      "Feature 62: -7.903690100254934e-05\n",
      "Feature 5: -0.00013365379582623848\n",
      "Feature 2: -0.00015433282556605034\n",
      "Feature 4: -0.00017445107738593978\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have X_train and y_train defined for training data\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVR(kernel=\"linear\")  # Replace 'rbf' with your desired kernel\n",
    "\n",
    "# Set the number of jobs to run in parallel (-1 means use all cores)\n",
    "svm_model.n_jobs = -1\n",
    "\n",
    "# Fit the SVM model to the training data\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Compute permutation importances\n",
    "result = permutation_importance(\n",
    "    svm_model, X_train, y_train, n_repeats=10, random_state=42\n",
    ")\n",
    "\n",
    "# Get feature importances\n",
    "importances = result.importances_mean\n",
    "\n",
    "# Create a list of feature names or indices paired with their importances\n",
    "feature_importances = list(zip(range(X_train.shape[1]), importances))\n",
    "\n",
    "# Sort the features based on importance in descending order\n",
    "feature_importances.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "# Print the ranked feature importances\n",
    "print(\"Feature Importances:\")\n",
    "for feature_index, importance in feature_importances:\n",
    "    print(f\"Feature {feature_index}: {importance}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter optimalisatie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |  epsilon  |   gamma   |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-925.1   \u001b[0m | \u001b[0m7.6      \u001b[0m | \u001b[0m0.2271   \u001b[0m | \u001b[0m0.06303  \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-936.7   \u001b[0m | \u001b[0m7.3      \u001b[0m | \u001b[0m0.9104   \u001b[0m | \u001b[0m0.006441 \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m-919.5   \u001b[0m | \u001b[95m7.821    \u001b[0m | \u001b[95m0.5609   \u001b[0m | \u001b[95m0.01775  \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-929.5   \u001b[0m | \u001b[0m4.383    \u001b[0m | \u001b[0m0.1734   \u001b[0m | \u001b[0m0.04306  \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-936.9   \u001b[0m | \u001b[0m5.961    \u001b[0m | \u001b[0m0.4892   \u001b[0m | \u001b[0m0.09859  \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-953.2   \u001b[0m | \u001b[0m0.4477   \u001b[0m | \u001b[0m0.377    \u001b[0m | \u001b[0m0.07085  \u001b[0m |\n",
      "| \u001b[95m7        \u001b[0m | \u001b[95m-918.7   \u001b[0m | \u001b[95m8.272    \u001b[0m | \u001b[95m0.3293   \u001b[0m | \u001b[95m0.02023  \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-931.6   \u001b[0m | \u001b[0m8.763    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1      \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-955.0   \u001b[0m | \u001b[0m9.26     \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m0.001    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-953.9   \u001b[0m | \u001b[0m3.514    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.001    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-932.7   \u001b[0m | \u001b[0m8.123    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.1      \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-932.2   \u001b[0m | \u001b[0m3.596    \u001b[0m | \u001b[0m0.7129   \u001b[0m | \u001b[0m0.04224  \u001b[0m |\n",
      "| \u001b[95m13       \u001b[0m | \u001b[95m-915.5   \u001b[0m | \u001b[95m8.976    \u001b[0m | \u001b[95m0.167    \u001b[0m | \u001b[95m0.03028  \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-920.2   \u001b[0m | \u001b[0m8.423    \u001b[0m | \u001b[0m0.05268  \u001b[0m | \u001b[0m0.01845  \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-929.5   \u001b[0m | \u001b[0m8.851    \u001b[0m | \u001b[0m0.8741   \u001b[0m | \u001b[0m0.0911   \u001b[0m |\n",
      "=============================================================\n",
      "RMSE: 28.63917404062013\n",
      "MSE: 820.2022897289299\n",
      "MAE: 10.558889048549553\n",
      "AED: [ 6.89495439  4.32065114 10.70576262 ...  4.51205409  5.36977962\n",
      "  5.1238842 ]\n",
      "R2: 0.08218179465021935\n",
      "Adjusted R2: 0.03384253212495736\n"
     ]
    }
   ],
   "source": [
    "# Define the SVM model evaluation function using cross-validation\n",
    "def evaluate_svm_model(C, epsilon, gamma):\n",
    "    # Create and configure the SVM model\n",
    "    model = SVR(C=C, epsilon=epsilon, gamma=gamma)\n",
    "\n",
    "    # Perform cross-validation on the training data\n",
    "    scores = cross_val_score(\n",
    "        model, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    "\n",
    "    # Return the negative mean squared error (Bayesian Optimization maximizes the objective)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Define the parameter ranges for Bayesian Optimization\n",
    "params_ranges = {\"C\": (0.1, 10), \"epsilon\": (0.01, 1), \"gamma\": (0.001, 0.1)}\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "svm_bo = BayesianOptimization(f=evaluate_svm_model, pbounds=params_ranges)\n",
    "svm_bo.maximize(n_iter=10, init_points=5)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = svm_bo.max[\"params\"]\n",
    "best_C = best_params[\"C\"]\n",
    "best_epsilon = best_params[\"epsilon\"]\n",
    "best_gamma = best_params[\"gamma\"]\n",
    "\n",
    "# Create the best SVM model with the tuned hyperparameters\n",
    "best_model_svm = SVR(C=best_C, epsilon=best_epsilon, gamma=best_gamma)\n",
    "\n",
    "# Fit the best model to the training data\n",
    "best_model_svm.fit(X_train, y_train)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "y_pred = best_model_svm.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "aed = np.abs(y_test.mean() - y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = len(X_test)\n",
    "k = X_test.shape[1]\n",
    "r2_adj = 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"AED:\", aed)\n",
    "print(\"R2:\", r2)\n",
    "print(\"Adjusted R2:\", r2_adj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "Feature 4: 0.3840647610385431\n",
      "Feature 1: 0.2981884698080396\n",
      "Feature 2: 0.2457994232800406\n",
      "Feature 3: 0.03343585402522996\n",
      "Feature 5: 0.007071879951101756\n",
      "Feature 6: 0.006205218866134093\n",
      "Feature 0: 0.0032810383832588097\n",
      "Feature 54: 0.0011590189297348953\n",
      "Feature 61: 0.001150611055955114\n",
      "Feature 30: 0.001025541827005766\n",
      "Feature 59: 0.00102264722726315\n",
      "Feature 25: 0.000884947470097738\n",
      "Feature 56: 0.0008620319104069063\n",
      "Feature 60: 0.0008218135380665498\n",
      "Feature 58: 0.0006907658275795227\n",
      "Feature 35: 0.0006555135416861213\n",
      "Feature 51: 0.0006534273842432839\n",
      "Feature 37: 0.0006504244393493843\n",
      "Feature 57: 0.0006222776324123562\n",
      "Feature 50: 0.0005195001412036058\n",
      "Feature 41: 0.0005175489294586262\n",
      "Feature 66: 0.0004627035406586939\n",
      "Feature 76: 0.00044625798875827017\n",
      "Feature 34: 0.0004155893022347489\n",
      "Feature 47: 0.000386056487099339\n",
      "Feature 74: 0.0003716963716032124\n",
      "Feature 36: 0.00034532082722209674\n",
      "Feature 65: 0.00032104282910793086\n",
      "Feature 29: 0.0003097749344213433\n",
      "Feature 71: 0.00029675841187584457\n",
      "Feature 52: 0.00028830618366517085\n",
      "Feature 62: 0.00028384684346069943\n",
      "Feature 64: 0.0002698783661411277\n",
      "Feature 55: 0.00026932472339002696\n",
      "Feature 69: 0.00024462650668526353\n",
      "Feature 16: 0.0002392002343133664\n",
      "Feature 73: 0.00022431429138940767\n",
      "Feature 75: 0.00022112637263162514\n",
      "Feature 40: 0.00021944423105603217\n",
      "Feature 38: 0.00021557467591597784\n",
      "Feature 32: 0.00021185189576996275\n",
      "Feature 7: 0.00020169050936312663\n",
      "Feature 9: 0.0001981422830003848\n",
      "Feature 43: 0.00019634701718374535\n",
      "Feature 8: 0.00018957623965025532\n",
      "Feature 42: 0.0001770346459187499\n",
      "Feature 21: 0.0001760851969240917\n",
      "Feature 22: 0.00017494821423296974\n",
      "Feature 15: 0.00017055171829656094\n",
      "Feature 17: 0.00016973356685077195\n",
      "Feature 44: 0.00016377907733395957\n",
      "Feature 33: 0.0001634742466504405\n",
      "Feature 48: 0.00016298270859410802\n",
      "Feature 19: 0.0001622666441551929\n",
      "Feature 45: 0.00016109823304795648\n",
      "Feature 53: 0.00015830036352668727\n",
      "Feature 18: 0.0001501522212601792\n",
      "Feature 67: 0.00014934183118883428\n",
      "Feature 72: 0.00013956272208793375\n",
      "Feature 10: 0.0001393521666269453\n",
      "Feature 11: 0.00013012507142505308\n",
      "Feature 49: 0.00012195998545545697\n",
      "Feature 24: 0.00011668772284325903\n",
      "Feature 27: 0.00010711753489160506\n",
      "Feature 39: 0.00010327745084909022\n",
      "Feature 23: 0.00010176595030943703\n",
      "Feature 12: 9.867824920287458e-05\n",
      "Feature 63: 9.586846294426974e-05\n",
      "Feature 46: 9.165280342016823e-05\n",
      "Feature 70: 9.060207573291313e-05\n",
      "Feature 28: 8.156044891445327e-05\n",
      "Feature 26: 7.84651575161969e-05\n",
      "Feature 68: 7.66527349525646e-05\n",
      "Feature 13: 7.158680138708448e-05\n",
      "Feature 31: 6.720373280066776e-05\n",
      "Feature 20: 2.735584774430288e-05\n",
      "Feature 14: 9.610139506806023e-06\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have X_train and y_train defined for training data\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Fit the Random Forest model to the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Create a list of feature names or indices paired with their importances\n",
    "feature_importances = list(zip(range(X_train.shape[1]), importances))\n",
    "\n",
    "# Sort the features based on importance in descending order\n",
    "feature_importances.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the ranked feature importances\n",
    "print(\"Feature Importances:\")\n",
    "for feature_index, importance in feature_importances:\n",
    "    print(f\"Feature {feature_index}: {importance}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter optimalisatie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | max_le... | min_sa... | min_we... | n_esti... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m23.48    \u001b[0m | \u001b[0m1.161    \u001b[0m | \u001b[0m0.9937   \u001b[0m | \u001b[0m83.45    \u001b[0m | \u001b[0m1.44     \u001b[0m | \u001b[0m0.4347   \u001b[0m | \u001b[0m68.38    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m22.23    \u001b[0m | \u001b[0m16.29    \u001b[0m | \u001b[0m0.8127   \u001b[0m | \u001b[0m34.73    \u001b[0m | \u001b[0m4.647    \u001b[0m | \u001b[0m0.3499   \u001b[0m | \u001b[0m84.96    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m19.11    \u001b[0m | \u001b[0m13.05    \u001b[0m | \u001b[0m0.6145   \u001b[0m | \u001b[0m83.83    \u001b[0m | \u001b[0m4.86     \u001b[0m | \u001b[0m0.05515  \u001b[0m | \u001b[0m45.47    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m20.13    \u001b[0m | \u001b[0m9.788    \u001b[0m | \u001b[0m0.1186   \u001b[0m | \u001b[0m19.57    \u001b[0m | \u001b[0m4.1      \u001b[0m | \u001b[0m0.1968   \u001b[0m | \u001b[0m92.6     \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m20.59    \u001b[0m | \u001b[0m5.048    \u001b[0m | \u001b[0m0.4126   \u001b[0m | \u001b[0m14.62    \u001b[0m | \u001b[0m7.17     \u001b[0m | \u001b[0m0.3088   \u001b[0m | \u001b[0m25.22    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m20.31    \u001b[0m | \u001b[0m17.76    \u001b[0m | \u001b[0m0.2147   \u001b[0m | \u001b[0m76.2     \u001b[0m | \u001b[0m5.388    \u001b[0m | \u001b[0m0.4011   \u001b[0m | \u001b[0m68.23    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m22.85    \u001b[0m | \u001b[0m8.119    \u001b[0m | \u001b[0m0.8833   \u001b[0m | \u001b[0m41.28    \u001b[0m | \u001b[0m2.888    \u001b[0m | \u001b[0m0.3158   \u001b[0m | \u001b[0m71.27    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m22.42    \u001b[0m | \u001b[0m3.371    \u001b[0m | \u001b[0m0.828    \u001b[0m | \u001b[0m29.85    \u001b[0m | \u001b[0m5.789    \u001b[0m | \u001b[0m0.3567   \u001b[0m | \u001b[0m75.32    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m11.28    \u001b[0m | \u001b[0m10.23    \u001b[0m | \u001b[0m0.6766   \u001b[0m | \u001b[0m32.88    \u001b[0m | \u001b[0m7.584    \u001b[0m | \u001b[0m0.004042 \u001b[0m | \u001b[0m92.75    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m19.78    \u001b[0m | \u001b[0m18.57    \u001b[0m | \u001b[0m0.2301   \u001b[0m | \u001b[0m32.29    \u001b[0m | \u001b[0m1.121    \u001b[0m | \u001b[0m0.04046  \u001b[0m | \u001b[0m64.66    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m20.74    \u001b[0m | \u001b[0m8.501    \u001b[0m | \u001b[0m0.1268   \u001b[0m | \u001b[0m52.4     \u001b[0m | \u001b[0m1.98     \u001b[0m | \u001b[0m0.07324  \u001b[0m | \u001b[0m31.94    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m22.75    \u001b[0m | \u001b[0m5.023    \u001b[0m | \u001b[0m0.8454   \u001b[0m | \u001b[0m24.93    \u001b[0m | \u001b[0m8.321    \u001b[0m | \u001b[0m0.1644   \u001b[0m | \u001b[0m65.68    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m19.35    \u001b[0m | \u001b[0m7.302    \u001b[0m | \u001b[0m0.2428   \u001b[0m | \u001b[0m21.97    \u001b[0m | \u001b[0m1.431    \u001b[0m | \u001b[0m0.02405  \u001b[0m | \u001b[0m73.7     \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m22.5     \u001b[0m | \u001b[0m17.05    \u001b[0m | \u001b[0m0.8638   \u001b[0m | \u001b[0m66.35    \u001b[0m | \u001b[0m5.739    \u001b[0m | \u001b[0m0.4322   \u001b[0m | \u001b[0m63.97    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m20.86    \u001b[0m | \u001b[0m3.004    \u001b[0m | \u001b[0m0.3504   \u001b[0m | \u001b[0m36.92    \u001b[0m | \u001b[0m2.246    \u001b[0m | \u001b[0m0.2941   \u001b[0m | \u001b[0m23.56    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m22.22    \u001b[0m | \u001b[0m9.687    \u001b[0m | \u001b[0m0.8073   \u001b[0m | \u001b[0m66.05    \u001b[0m | \u001b[0m1.895    \u001b[0m | \u001b[0m0.3226   \u001b[0m | \u001b[0m14.51    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m16.84    \u001b[0m | \u001b[0m16.62    \u001b[0m | \u001b[0m0.2302   \u001b[0m | \u001b[0m76.1     \u001b[0m | \u001b[0m8.954    \u001b[0m | \u001b[0m0.001228 \u001b[0m | \u001b[0m28.19    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m23.13    \u001b[0m | \u001b[0m4.848    \u001b[0m | \u001b[0m0.9353   \u001b[0m | \u001b[0m83.64    \u001b[0m | \u001b[0m7.655    \u001b[0m | \u001b[0m0.4516   \u001b[0m | \u001b[0m48.16    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m20.76    \u001b[0m | \u001b[0m17.29    \u001b[0m | \u001b[0m0.2612   \u001b[0m | \u001b[0m99.2     \u001b[0m | \u001b[0m1.832    \u001b[0m | \u001b[0m0.1727   \u001b[0m | \u001b[0m60.62    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m21.83    \u001b[0m | \u001b[0m18.65    \u001b[0m | \u001b[0m0.6056   \u001b[0m | \u001b[0m49.49    \u001b[0m | \u001b[0m3.284    \u001b[0m | \u001b[0m0.1443   \u001b[0m | \u001b[0m71.28    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m20.47    \u001b[0m | \u001b[0m8.795    \u001b[0m | \u001b[0m0.1254   \u001b[0m | \u001b[0m51.9     \u001b[0m | \u001b[0m9.06     \u001b[0m | \u001b[0m0.116    \u001b[0m | \u001b[0m43.09    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m20.51    \u001b[0m | \u001b[0m3.343    \u001b[0m | \u001b[0m0.3786   \u001b[0m | \u001b[0m35.8     \u001b[0m | \u001b[0m5.368    \u001b[0m | \u001b[0m0.3657   \u001b[0m | \u001b[0m57.63    \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m20.77    \u001b[0m | \u001b[0m9.799    \u001b[0m | \u001b[0m0.4417   \u001b[0m | \u001b[0m53.16    \u001b[0m | \u001b[0m1.402    \u001b[0m | \u001b[0m0.3291   \u001b[0m | \u001b[0m31.77    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m23.41    \u001b[0m | \u001b[0m1.738    \u001b[0m | \u001b[0m0.9957   \u001b[0m | \u001b[0m83.52    \u001b[0m | \u001b[0m2.858    \u001b[0m | \u001b[0m0.4421   \u001b[0m | \u001b[0m63.76    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m22.71    \u001b[0m | \u001b[0m1.63     \u001b[0m | \u001b[0m0.8385   \u001b[0m | \u001b[0m81.53    \u001b[0m | \u001b[0m7.5      \u001b[0m | \u001b[0m0.2972   \u001b[0m | \u001b[0m67.78    \u001b[0m |\n",
      "=================================================================================================\n",
      "MSE: 821.2009853097334\n",
      "MAE: 14.997941593375153\n",
      "AED: [8.71694362 9.92372156 8.71694362 ... 8.8534001  8.8534001  9.04549794]\n",
      "R2: 0.0810642398748399\n",
      "Adjusted R2: 0.03266611844553946\n",
      "RMSE: 28.656604567005726\n"
     ]
    }
   ],
   "source": [
    "params_ranges = {\n",
    "    \"n_estimators\": (10, 100),\n",
    "    \"max_depth\": (1, 20),\n",
    "    \"min_samples_leaf\": (1, 10),\n",
    "    \"min_weight_fraction_leaf\": (0.0, 0.5),\n",
    "    \"max_features\": (0.1, 1),\n",
    "    \"max_leaf_nodes\": (10, 100),\n",
    "}\n",
    "\n",
    "# Example usage with Random Forest\n",
    "model = RandomForestRegressor\n",
    "dt_bo = BayesianOptimization(\n",
    "    f=lambda n_estimators, max_depth, min_samples_leaf, min_weight_fraction_leaf, max_features, max_leaf_nodes: bo_params_generic(\n",
    "        model,\n",
    "        {\n",
    "            \"n_estimators\": int(round(n_estimators)),\n",
    "            \"max_depth\": int(round(max_depth)),\n",
    "            \"min_samples_leaf\": round(min_samples_leaf),\n",
    "            \"min_weight_fraction_leaf\": min_weight_fraction_leaf,\n",
    "            \"max_features\": max_features,\n",
    "            \"max_leaf_nodes\": int(round(max_leaf_nodes)),\n",
    "        },\n",
    "        X_train,\n",
    "        y_train,\n",
    "    ),\n",
    "    pbounds=params_ranges,\n",
    ")\n",
    "results = dt_bo.maximize(n_iter=5, init_points=20)\n",
    "params = dt_bo.max[\"params\"]\n",
    "\n",
    "# Creating a model with the best hyperparameters\n",
    "best_model_random_forest = model(\n",
    "    n_estimators=int(round(params[\"n_estimators\"])),\n",
    "    max_depth=int(round(params[\"max_depth\"])),\n",
    "    min_samples_leaf=round(params[\"min_samples_leaf\"]),\n",
    "    min_weight_fraction_leaf=params[\"min_weight_fraction_leaf\"],\n",
    "    max_features=params[\"max_features\"],\n",
    "    max_leaf_nodes=int(round(params[\"max_leaf_nodes\"])),\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "best_model_random_forest.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_pred = best_model_random_forest.predict(X_test)\n",
    "\n",
    "mse_scores = mean_squared_error(y_test, y_pred)\n",
    "mae_scores = mean_absolute_error(y_test, y_pred)\n",
    "aed_scores = np.abs(y_test.mean() - y_pred)\n",
    "r2_scores = r2_score(y_test, y_pred)\n",
    "\n",
    "n = len(X_test)\n",
    "k = X_test.shape[1]\n",
    "r2_adj_scores = 1 - (1 - r2_scores) * ((n - 1) / (n - k - 1))\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "print(\"MSE:\", mse_scores)\n",
    "print(\"MAE:\", mae_scores)\n",
    "print(\"AED:\", aed_scores)\n",
    "print(\"R2:\", r2_scores)\n",
    "print(\"Adjusted R2:\", r2_adj_scores)\n",
    "print(\"RMSE:\", rmse_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "when `importance_getter=='auto'`, the underlying estimator MLPRegressor should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39m# Perform feature selection using Recursive Feature Elimination (RFE)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m selector \u001b[39m=\u001b[39m RFE(estimator\u001b[39m=\u001b[39mnn_model, n_features_to_select\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)  \u001b[39m# Adjust n_features_to_select as needed\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m selector\u001b[39m.\u001b[39;49mfit(X_train_scaled, y_train)\n\u001b[0;32m     24\u001b[0m \u001b[39m# Transform the training and testing sets to keep only the selected features\u001b[39;00m\n\u001b[0;32m     25\u001b[0m X_train_selected \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39mtransform(X_train_scaled)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\feature_selection\\_rfe.py:251\u001b[0m, in \u001b[0;36mRFE.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \n\u001b[0;32m    233\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 251\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\feature_selection\\_rfe.py:302\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    299\u001b[0m estimator\u001b[39m.\u001b[39mfit(X[:, features], y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    301\u001b[0m \u001b[39m# Get importance and rank them\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m importances \u001b[39m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    303\u001b[0m     estimator,\n\u001b[0;32m    304\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimportance_getter,\n\u001b[0;32m    305\u001b[0m     transform_func\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msquare\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    306\u001b[0m )\n\u001b[0;32m    307\u001b[0m ranks \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(importances)\n\u001b[0;32m    309\u001b[0m \u001b[39m# for sparse case ranks is matrix\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\feature_selection\\_base.py:208\u001b[0m, in \u001b[0;36m_get_feature_importances\u001b[1;34m(estimator, getter, transform_func, norm_order)\u001b[0m\n\u001b[0;32m    206\u001b[0m         getter \u001b[39m=\u001b[39m attrgetter(\u001b[39m\"\u001b[39m\u001b[39mfeature_importances_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    207\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    209\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwhen `importance_getter==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`, the underlying \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    210\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mestimator \u001b[39m\u001b[39m{\u001b[39;00mestimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m should have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    211\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`coef_` or `feature_importances_` attribute. Either \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mpass a fitted estimator to feature selector or call fit \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mbefore calling transform.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     getter \u001b[39m=\u001b[39m attrgetter(getter)\n",
      "\u001b[1;31mValueError\u001b[0m: when `importance_getter=='auto'`, the underlying estimator MLPRegressor should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform."
     ]
    }
   ],
   "source": [
    "# Assuming you have X and y defined for the dataset\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the neural network regressor\n",
    "nn_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(10, 10)\n",
    ")  # Adjust the architecture as needed\n",
    "\n",
    "# Set the number of jobs to run in parallel (-1 means use all cores)\n",
    "nn_model.n_jobs = -1\n",
    "\n",
    "# Fit the neural network model to the training data\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Perform feature selection using Recursive Feature Elimination (RFE)\n",
    "selector = RFE(\n",
    "    estimator=nn_model, n_features_to_select=10\n",
    ")  # Adjust n_features_to_select as needed\n",
    "selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Transform the training and testing sets to keep only the selected features\n",
    "X_train_selected = selector.transform(X_train_scaled)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Print the selected feature support\n",
    "selected_support = selector.support_\n",
    "print(\"Selected Feature Support:\")\n",
    "print(selected_support)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter optimalisatie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ranges = {\n",
    "    \"hidden_layer_sizes\": (10, 100),\n",
    "    \"alpha\": (0.0001, 0.1),\n",
    "    \"learning_rate_init\": (0.001, 0.1),\n",
    "    \"max_iter\": (100, 1000),\n",
    "}\n",
    "\n",
    "# Example usage with Neural Network\n",
    "model = MLPRegressor\n",
    "dt_bo = BayesianOptimization(\n",
    "    f=lambda hidden_layer_sizes, alpha, learning_rate_init, max_iter: bo_params_generic(\n",
    "        model,\n",
    "        {\n",
    "            \"hidden_layer_sizes\": (int(round(hidden_layer_sizes)),),\n",
    "            \"alpha\": alpha,\n",
    "            \"learning_rate_init\": learning_rate_init,\n",
    "            \"max_iter\": int(round(max_iter)),\n",
    "        },\n",
    "        X_train,\n",
    "        y_train,\n",
    "    ),\n",
    "    pbounds=params_ranges,\n",
    ")\n",
    "\n",
    "results = dt_bo.maximize(n_iter=5, init_points=20)\n",
    "params = dt_bo.max[\"params\"]\n",
    "\n",
    "# Creating a model with the best hyperparameters\n",
    "best_model_neural_network = model(\n",
    "    hidden_layer_sizes=(int(round(params[\"hidden_layer_sizes\"])),),\n",
    "    alpha=params[\"alpha\"],\n",
    "    learning_rate_init=params[\"learning_rate_init\"],\n",
    "    max_iter=int(round(params[\"max_iter\"])),\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "best_model_neural_network.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "aed = np.abs(y_test.mean() - y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = len(X_test)\n",
    "k = X_test.shape[1]\n",
    "r2_adj = 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"AED:\", aed)\n",
    "print(\"R2:\", r2)\n",
    "print(\"Adjusted R2:\", r2_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append model to list\n",
    "all_models[\"Random forest\"] = best_model_random_forest\n",
    "all_models[\"SVM\"] = best_model_svm\n",
    "all_models[\"Neural Network\"] = best_model_neural_network\n",
    "all_models[\"MLR\"] = best_model_mlr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting the bar chart"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metric labels\n",
    "metric_labels = [\"RMSE\", \"MSE\", \"MAE\", \"AED\", \"R2\", \"Adjusted R2\"]\n",
    "\n",
    "# Calculate evaluation metrics using cross-validation for each model\n",
    "metrics = {\n",
    "    \"RMSE\": lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    \"MSE\": mean_squared_error,\n",
    "    \"MAE\": mean_absolute_error,\n",
    "    \"AED\": lambda y_true, y_pred: np.abs(np.mean(y_true) - y_pred),\n",
    "    \"R2\": r2_score,\n",
    "    \"Adjusted R2\": lambda y_true, y_pred: 1\n",
    "    - (\n",
    "        (1 - r2_score(y_true, y_pred))\n",
    "        * (len(y_true) - 1)\n",
    "        / (len(y_true) - X_train.shape[1] - 1)\n",
    "    ),\n",
    "}\n",
    "\n",
    "model_names = [\"Random Forest\", \"SVM\", \"Neural Network\", \"MLR\"]\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": best_model_random_forest,\n",
    "    \"SVM\": best_model_svm,\n",
    "    \"Neural Network\": best_model_neural_network,\n",
    "    \"MLR\": best_model_mlr,\n",
    "}\n",
    "\n",
    "metric_scores = {metric: [] for metric in metric_labels}\n",
    "\n",
    "for model_name in model_names:\n",
    "    model = models[model_name]\n",
    "    y_pred = cross_val_predict(model, X_train, y_train, cv=5)\n",
    "    for metric in metric_labels:\n",
    "        metric_scores[metric].append(metrics[metric](y_train, y_pred))\n",
    "\n",
    "# Plotting the bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "for metric in metric_labels:\n",
    "    fig.add_trace(go.Bar(x=model_names, y=metric_scores[metric], name=metric))\n",
    "\n",
    "# Updating the layout\n",
    "fig.update_layout(\n",
    "    title=\"Evaluation Metrics Comparison\",\n",
    "    xaxis_title=\"Models\",\n",
    "    yaxis_title=\"Scores\",\n",
    "    barmode=\"group\",\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**using test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metric labels\n",
    "metric_labels = [\"RMSE\", \"MSE\", \"MAE\", \"AED\", \"R2\", \"Adjusted R2\"]\n",
    "\n",
    "# Calculate evaluation metrics using cross-validation for each model\n",
    "metrics = {\n",
    "    \"RMSE\": lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    \"MSE\": mean_squared_error,\n",
    "    \"MAE\": mean_absolute_error,\n",
    "    \"AED\": lambda y_true, y_pred: np.abs(np.mean(y_true) - y_pred),\n",
    "    \"R2\": r2_score,\n",
    "    \"Adjusted R2\": lambda y_true, y_pred: 1\n",
    "    - (\n",
    "        (1 - r2_score(y_true, y_pred))\n",
    "        * (len(y_true) - 1)\n",
    "        / (len(y_true) - X_train.shape[1] - 1)\n",
    "    ),\n",
    "}\n",
    "\n",
    "model_names = [\"Random Forest\", \"SVM\", \"Neural Network\", \"MLR\"]\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": best_model_random_forest,\n",
    "    \"SVM\": best_model_svm,\n",
    "    \"Neural Network\": best_model_neural_network,\n",
    "    \"MLR\": best_model_mlr,\n",
    "}\n",
    "\n",
    "# Train each model on the training data and predict the test data\n",
    "predictions = {}\n",
    "for model_name in model_names:\n",
    "    model = models[model_name]\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    predictions[model_name] = model.predict(X_test)  # Predict the test data\n",
    "\n",
    "# Calculate each metric for each model's predictions\n",
    "metric_scores = {metric: [] for metric in metric_labels}\n",
    "for model_name in model_names:\n",
    "    y_pred = predictions[model_name]\n",
    "    for metric in metric_labels:\n",
    "        metric_scores[metric].append(\n",
    "            metrics[metric](y_test, y_pred)\n",
    "        )  # Use the test data here\n",
    "\n",
    "# Plotting the bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "for metric in metric_labels:\n",
    "    fig.add_trace(go.Bar(x=model_names, y=metric_scores[metric], name=metric))\n",
    "\n",
    "# Updating the layout\n",
    "fig.update_layout(\n",
    "    title=\"Evaluation Metrics Comparison\",\n",
    "    xaxis_title=\"Models\",\n",
    "    yaxis_title=\"Scores\",\n",
    "    barmode=\"group\",\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
